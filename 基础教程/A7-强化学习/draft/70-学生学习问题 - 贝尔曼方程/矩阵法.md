


### 矩阵法

观察式 10 方程组，可以把它变形为：

$$
\begin{bmatrix}
v_0
\\
v_1
\\
v_2
\\
v_3
\\
v_4
\\
v_5
\\
v_6
\end{bmatrix}
= \
\begin{bmatrix}
-1
\\
-2
\\
-2
\\
-2
\\
10
\\
1
\\
0
\end{bmatrix}
+\gamma 
\begin{bmatrix}
0.9v_0+0.1v_1
\\
0.5v_0+0.5v_2
\\
0.8v_3+0.2v_6
\\
0.6v_4+0.4v_5
\\
v_6
\\
0.2v_1+0.4v_2+0.4v_3
\\
0
\end{bmatrix}
\tag{13}
$$


关于式 13：

- 等式左侧的部分，就是状态值的向量，可以写成 $V_s$。
- 等式右侧的第一项，就是状态上的奖励值组成的向量，可以写成 $R_s$。
- 等式右侧的第二个矩阵，又可以写成两个矩阵的乘积：

$$
\begin{bmatrix}
0.9 & 0.1 & 0 & 0 & 0 & 0 & 0
\\
0.5 & 0 & 0.5 & 0 & 0 & 0 & 0
\\
0 & 0 & 0 & 0.8 & 0 & 0 & 0.2
\\
0 & 0 & 0 & 0 & 0.6 & 0.4 & 0
\\
0 & 0 & 0 & 0 & 0 & 0 & 1.0
\\
0 & 0.2 & 0.4 & 0.4 & 0 & 0 & 0
\\
0 & 0 & 0 & 0 & 0 & 0 & 1.0
\end{bmatrix}
\begin{bmatrix}
v_0
\\
v_1
\\
v_2
\\
v_3
\\
v_4
\\
v_5
\\
v_6
\end{bmatrix}
\tag{14}
$$

其中，第一个矩阵就是该问题的状态转移矩阵 $P_{ss'}$，第二个矩阵是状态值向量 $V_s$，于是，式 9 可以变成：
$$
V_s = R_s+ \gamma P_{ss'}V_s \tag{15}
$$

从式 9 直接看过来，式 15 等式右侧的 $V_s$ 应该是 $V_{s'}$ 才对，即 $V_s = R_s+\gamma P_{ss'}V_{s'}$。但是经过上述的实例化推导，读者可以理解所谓的 $V_{s'}$ 是在时间维度上的定义，表示下一步的状态；而在空间上，由于状态值一旦确定就不会变化，并没有 $s'$ 的概念。

比如：
- 式 10.4，$v_3=-2+ (0.6 v_4 + 0.4 v_5)$ 中，$V_s=v_3,V_{s'}=\{v_4,v_5\}$，$v_5$ 是 $v_3$ 的后续状态。
- 式 10.6，$v_5=1+0.2v_1+0.4v_2+0.4v_3$ 中，$V_s=v_5,V_{s'}=\{v_1,v_2,v_3\}$，$v_3$ 是 $v_5$ 的后续状态。

两者在不同的马尔可夫过程中互为后续状态，所以实际上并没有 $V_{s'}$ 的概念，或者说 $V_s$ 和 $V_{s'}$ 对于具体的状态实例有区别，对于状态向量组没有区别。

对于式 13 的一个泛化的形式是式 16：

$$
\begin{bmatrix}
V_1
\\
V_2
\\
\vdots
\\
V_n
\end{bmatrix}
=\
\begin{bmatrix}
R_1
\\
R_2
\\
\vdots
\\
R_n
\end{bmatrix}
+\gamma
\begin{bmatrix}
P_{11} & P_{12} & \cdots & P_{1n}
\\
P_{21} & P_{22} & \cdots & P_{2n}
\\
\vdots & \vdots & \ddots & \vdots
\\
P_{n1} & P_{n2} & \cdots & P_{nn}
\end{bmatrix}
\begin{bmatrix}
V_1
\\
V_2
\\
\vdots
\\
V_n
\end{bmatrix}
\tag{16}
$$


式 15 可以变形，并最终解出 $V_s$：

$$
\begin{aligned}
V_s &= R_s+ \gamma P_{ss'}V_s
\\
V_s - \gamma P_{ss'}V_s &= R_s
\\
(I-\gamma P_{ss'})V_s&=R_s, &(I \ {\footnotesize 是对角矩阵})
\\
V_s&=(I-\gamma P_{ss'})^{-1}R_s
\end{aligned}
\tag{17}
$$

式 16 中，等式右侧的值都是已知的，所以可以解出 $V_s$ 的数学解析解。

定义状态转移矩阵：

```python
# 状态转移概率
P = np.array(
    [   #Game Cl1  Cl2  Cl3  Pass Rest End
        [0.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0], 
        [0.5, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0],
        [0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.2],
        [0.0, 0.0, 0.0, 0.0, 0.6, 0.4, 0.0],
        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],
        [0.0, 0.2, 0.4, 0.4, 0.0, 0.0, 0.0],
        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0] 
    ]
)
```

定义奖励函数值向量：
```python
# 奖励向量
# [Game, Class1, Class2, Class3, Pass, Rest, End]
Rewards = [-1, -2, -2, -2, 10, 1, 0]
```
代码
    
```python 
def SolveMatrix(dataModel, gamma):
    # 在对角矩阵上增加一个微小的值来解决奇异矩阵不可求逆的问题
    I = np.eye(dataModel.N) * (1+1e-7)
    # I = np.eye(dataModel.N) # 非奇异矩阵时使用此行代码以提高计算精度
    factor = I - gamma * dataModel.P
    inv_factor = np.linalg.inv(factor)
    vs = np.dot(inv_factor, dataModel.R)
    return vs
```
在定义状态转移矩阵时，右下角的值，即从 $S_{End} \to S_{End}$ 的转移概率，即可以写成 0.0，也可以写成 1.0，从强化学习的概念角度出发，都没有错。

与代码处理逻辑有关。

写成 0.0 时，np.random.choice(p=) 函数由于概率之和不为 1，所以函数调用出错。
写成 1.0 时，由于矩阵的行列式为 0，是个奇异矩阵，不可求逆。此时可以在对角矩阵上增加一个微小的值来解决奇异矩阵不可求逆的问题，但是最终结果会有 1e-7 的误差，可以接受。

```
[-22.54320988 -12.54320988   1.45679012   4.32098765  10.   0.80246914   0.        ]
Game:   -22.543
Class1: -12.543
Class2: 1.457
Class3: 4.321
Pass:   10.0
Rest:   0.802
End:    0.0
```

可能有读者好奇：用矩阵法得到的结果，与式 12 相比，哪一个更准确？

答案是：式 12 更准确。原因是用代码求矩阵的逆时，由于具体实现的问题有一些误差，否则的话两者应该完全相等。

### 迭代法（动态规划）
